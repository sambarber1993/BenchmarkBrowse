{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c846a5c-dff4-40a5-835a-4768f09a6e61",
   "metadata": {},
   "source": [
    "#Load required inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5a3e45c-49df-4e65-b66b-cf52e110cc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.figure import Figure \n",
    "from matplotlib import dates as mdates\n",
    "import datetime\n",
    "from ipywidgets import interact, interactive, fixed, Layout, HBox, VBox\n",
    "from IPython.display import clear_output, display\n",
    "import ipywidgets as widgets\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.ticker as mtick\n",
    "import snowflake.connector\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "rcParams.update({'figure.autolayout': True})\n",
    "pd.options.mode.chained_assignment = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e27f2b4c-1dd0-4b25-b486-bfa33317d077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f7fad1f-dad7-46a2-9087-ce38a68d8071",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"user\": \"SBARBER\",\n",
    "    \"password\": \"1Likespurs\",\n",
    "    \"account\": \"rimes-aws_eu_west_01\",\n",
    "    \"warehouse\": \"PUBLIC_WH\",\n",
    "    \"session_parameters\":{\n",
    "       \n",
    "    }\n",
    "}\n",
    "   \n",
    "\n",
    "sf_con = snowflake.connector.connect(**config)\n",
    "\n",
    "def query_sf(sf_con, sql, params=None):\n",
    "    cur = sf_con.cursor()\n",
    "    try:\n",
    "        if params:\n",
    "            cur.execute(sql, params)  # Execute with parameters\n",
    "        else:\n",
    "            cur.execute(sql)  # Execute without parameters\n",
    "        return cur.fetch_pandas_all()\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing query: {e}\")\n",
    "    finally:\n",
    "        cur.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55476082-9007-4365-8e19-d2d2379a4419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "daa67ad9-8946-4e4b-9d57-94b3bd55a5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load etf and index constituent data\n",
    "\n",
    "\n",
    "query_params = {\n",
    "    'target_date': '2024-02-13'\n",
    "}\n",
    "\n",
    "indexcons = \"\"\"\n",
    "SELECT IndexID, Isin, Weight, Effective_Date, view_type \n",
    "FROM indexdepot_ftp_euwest1.public.rimes_idx_constituents\n",
    "WHERE Effective_Date = %(target_date)s AND view_type = 'COB'  and Feed_Version='1'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Use the query_sf function to execute the SQL and fetch the results into a DataFrame\n",
    "idx_cons = query_sf(sf_con, indexcons,query_params)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "etfcons = \"\"\"\n",
    "SELECT concat(etfsource,'|',etfsymbol) as etfsymbol, Isin, Iwght as Weight, Date as Effective_Date\n",
    "FROM ETFDEPOT_FTP_EUWEST1.PUBLIC.PRICING_ETF\n",
    "where Date=%(target_date)s and Version='0' and Isin is not null\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Use the query_sf function to execute the SQL and fetch the results into a DataFrame\n",
    "etf_cons = query_sf(sf_con, etfcons, query_params)\n",
    "\n",
    "etf_cons = etf_cons[etf_cons['WEIGHT'] > 0]\n",
    "\n",
    "\n",
    "\n",
    "idxreturns = \"\"\"\n",
    "    SELECT distinct\n",
    "        Date, IndexID, IndexReturn1D\n",
    "    FROM indexdepot_ftp_euwest1.public.RIMES_IDX_LEVEL i where Feed_Version='1'\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Use the query_sf function to execute the SQL and fetch the results into a DataFrame\n",
    "idx_returns = query_sf(sf_con, idxreturns, query_params)\n",
    "\n",
    "\n",
    "\n",
    "etfreturns = \"\"\"\n",
    "    select * from (SELECT\n",
    "    concat(n.etfsource,'|',n.etfsymbol) as etfsymbol,\n",
    "    n.pricedate AS Date,\n",
    "    n.NAV,\n",
    "    LAG(n.NAV) OVER (PARTITION BY n.ETFSYMBOL ORDER BY n.pricedate ASC) AS PrevNAV,\n",
    "    (n.NAV - LAG(n.NAV) OVER (PARTITION BY n.ETFSYMBOL ORDER BY n.pricedate ASC)) \n",
    "    / NULLIF(LAG(n.NAV) OVER (PARTITION BY n.ETFSYMBOL ORDER BY n.pricedate ASC), 0) AS ETFReturn1D\n",
    "FROM ETFDEPOT_FTP_EUWEST1.PUBLIC.NAV_ETF n where Version='0') where ETFReturn1D is not null\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Use the query_sf function to execute the SQL and fetch the results into a DataFrame\n",
    "etf_returns = query_sf(sf_con, etfreturns, query_params)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Use the query_sf function to execute the SQL and fetch the results into a DataFrame\n",
    "idx_returns = query_sf(sf_con, idxreturns, query_params)\n",
    "\n",
    "\n",
    "\n",
    "etfcatalog = \"\"\"\n",
    "    SELECT distinct\n",
    "        concat(etfsource,'|',etfsymbol) as etfsymbol, desc as description, baseccy\n",
    "    FROM ETFDEPOT_FTP_EUWEST1.PUBLIC.NAV_ETF e  where Version='0'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Use the query_sf function to execute the SQL and fetch the results into a DataFrame\n",
    "etf_catalog = query_sf(sf_con, etfcatalog, query_params)\n",
    "\n",
    "\n",
    "idxcatalog = \"\"\"\n",
    "    SELECT distinct\n",
    "        indexid, description, indexccy, returntype\n",
    "    FROM indexdepot_ftp_euwest1.public.RIMES_IDX\n",
    "    WHERE  Date=%(target_date)s\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Use the query_sf function to execute the SQL and fetch the results into a DataFrame\n",
    "idx_catalog = query_sf(sf_con, idxcatalog, query_params)\n",
    "\n",
    "\n",
    "# Restriction so we can match on non variants\n",
    "idx_catalog['MatchID'] = idx_catalog['INDEXID'].apply(lambda x: '|'.join(x.split('|')[:2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3983d341-670d-492a-ba4e-e4c197fa7b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get index to index overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39f06265-44cf-4d85-a144-4b1914fc32a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def analyze_index_overlap(idx_id, idx_cons, idx_catalog):\n",
    "    \"\"\"\n",
    "    Analyze overlap for a specific index against all other indexes.\n",
    "\n",
    "    Parameters:\n",
    "    - idx_id: The ID of the index to analyze.\n",
    "    - idx_cons: DataFrame containing index constituents information.\n",
    "    - idx_catalog: DataFrame with index catalog information.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame containing top overlaps for the specified index.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define a function to handle empty groups within the groupby.apply()\n",
    "    def sum_weights(x):\n",
    "        return pd.Series({\n",
    "            'WEIGHTA': x['WEIGHT_x'].sum(),\n",
    "            'WEIGHTB': x['WEIGHT_y'].sum()\n",
    "        })\n",
    "    \n",
    "    # Filter idx_cons for the current index\n",
    "    filtered_idx_cons = idx_cons[idx_cons['INDEXID'] == idx_id]\n",
    "\n",
    "    # Create a merged DataFrame from filtered_idx_cons on idx_cons with conditions\n",
    "    merged = filtered_idx_cons.merge(idx_cons, on='ISIN', suffixes=('_x', '_y'))\n",
    "\n",
    "\n",
    "    # Filter out rows where IndexID_x == IndexID_y\n",
    "    merged_filtered = merged[merged['INDEXID_x'] != merged['INDEXID_y']].copy()\n",
    "\n",
    "\n",
    "    # Sum weights for each IndexID pair\n",
    "    common_constituents = merged_filtered.groupby(['INDEXID_x', 'INDEXID_y'], as_index=False).apply(sum_weights)\n",
    "\n",
    "\n",
    "    # Calculate the minimum weight directly within the merged_filtered DataFrame\n",
    "    merged_filtered['MIN_WEIGHT'] = merged_filtered[['WEIGHT_x', 'WEIGHT_y']].min(axis=1)\n",
    "  \n",
    "    # Calculate the overlap coefficient for each pair of indexes\n",
    "    overlap_coefficient = merged_filtered.groupby(['INDEXID_x', 'INDEXID_y'])['MIN_WEIGHT'].sum().reset_index()\n",
    "    overlap_coefficient.rename(columns={'MIN_WEIGHT': 'OVERLAP'}, inplace=True)\n",
    "    \n",
    "    # Modify UniqueIndexB to capture the first two segments if necessary\n",
    "    overlap_coefficient['UniqueIndexB'] = overlap_coefficient['INDEXID_y'].apply(lambda x: '|'.join(x.split('|')[:2]))\n",
    "    \n",
    "    # Calculate the maximum overlap for each unique Index B group\n",
    "    max_overlap = overlap_coefficient.groupby(['INDEXID_x', 'UniqueIndexB'])['OVERLAP'].max().reset_index()\n",
    "    \n",
    "    # Rank and select top overlaps\n",
    "    max_overlap['RANK'] = max_overlap.groupby('INDEXID_x')['OVERLAP'].rank(method='dense', ascending=False)\n",
    "    \n",
    "    # Filter to get the top 10 overlaps for each INDEXID_x\n",
    "    top_overlaps = max_overlap[max_overlap['RANK'] <= 10].sort_values(by=['INDEXID_x', 'RANK'])\n",
    "    \n",
    "    # Assign MatchID for merging with idx_catalog\n",
    "    top_overlaps['MatchID'] = top_overlaps['UniqueIndexB']\n",
    "    \n",
    "    # Merging top_overlaps with idx_catalog based on MatchID\n",
    "    idx_overlaps = pd.merge(top_overlaps, idx_catalog, on='MatchID', how='left', suffixes=('', '_catalog'))\n",
    "    \n",
    "    return idx_overlaps\n",
    "\n",
    "# Example usage:\n",
    "# idx_id = 'YourIndexIDHere'\n",
    "# idx_overlaps_for_index = analyze_index_overlap(idx_id, idx_cons, idx_catalog)\n",
    "# print(idx_overlaps_for_index)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc6a2961-ed20-4954-8627-1f4338e5e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get ETF to Index overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07c5facf-1535-409d-ad54-4af6e2d4ee9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def analyze_etf_index_overlap(idx_id, idx_cons, etf_cons, idx_catalog):\n",
    "    \"\"\"\n",
    "    Analyze overlap for a specific ETF against index constituents.\n",
    "    \n",
    "    Parameters:\n",
    "    - etf_id: The ID of the ETF to analyze.\n",
    "    - idx_cons: DataFrame containing index constituents information.\n",
    "    - etf_cons: DataFrame containing ETF constituents information.\n",
    "    - idx_catalog: DataFrame with index catalog information.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with overlap analysis for the specified ETF against indexes.\n",
    "    \"\"\"\n",
    "    # Filter etf_cons for the specific ETF\n",
    "    filtered_etf_cons = etf_cons[etf_cons['ETFSYMBOL'] == idx_id]\n",
    "    \n",
    "    # Adjust idx_cons columns for merging\n",
    "    idx_cons_adjusted = idx_cons.rename(columns={'INDEXID': 'ETFSymbol', 'ISIN': 'ISIN', 'WEIGHT': 'WEIGHT', 'EFFECTIVE_DATE': 'EFFECTIVE_DATE'})\n",
    "\n",
    "    # Merge filtered_etf_cons and idx_cons_adjusted on ISIN\n",
    "    merged = filtered_etf_cons.merge(idx_cons_adjusted, on='ISIN', suffixes=('_etf', '_idx'))\n",
    "    # Calculate minimum weight for each ISIN pair\n",
    "    merged['MIN_WEIGHT'] = merged[['WEIGHT_etf', 'WEIGHT_idx']].min(axis=1)\n",
    "\n",
    "    # Calculate total overlap for each index\n",
    "    etf_index_overlaps = merged.groupby('ETFSymbol')['MIN_WEIGHT'].sum().reset_index()\n",
    "    etf_index_overlaps.rename(columns={'ETFSymbol': 'INDEXID', 'MIN_WEIGHT': 'OVERLAP'}, inplace=True)\n",
    "    \n",
    "    # Assign ETFSymbol\n",
    "    etf_index_overlaps['ETFSymbol'] = idx_id\n",
    "\n",
    "    # Sort by OVERLAP in descending order and calculate RANK\n",
    "    etf_index_overlaps = etf_index_overlaps.sort_values(by='OVERLAP', ascending=False).reset_index(drop=True)\n",
    "    etf_index_overlaps['RANK'] = etf_index_overlaps['OVERLAP'].rank(method='dense', ascending=False)\n",
    "    \n",
    "    # Reorder columns to align with the expected output format\n",
    "    etf_index_overlaps = etf_index_overlaps[['ETFSymbol', 'INDEXID', 'OVERLAP', 'RANK']]\n",
    "\n",
    "    return etf_index_overlaps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c39f6671-ee39-4a23-86b8-f7e8d9d31ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Index to ETF overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3eafb0dc-cd93-4426-b388-28e67a3a8951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def analyze_index_etf_overlap(idx_id, idx_cons, etf_cons, idx_catalog):\n",
    "    \"\"\"\n",
    "    Analyze overlap for a specific index against ETF constituents.\n",
    "    \"\"\"\n",
    "    filtered_idx_cons = idx_cons[idx_cons['INDEXID'] == idx_id]\n",
    "    \n",
    "    # Adjust etf_cons columns for merging\n",
    "    etf_cons_adjusted = etf_cons.rename(columns={'ETFSYMBOL': 'INDEXID', 'Isin': 'ISIN', 'WEIGHT': 'WEIGHT', 'EFFECTIVE_DATE': 'EFFECTIVE_DATE'})\n",
    "\n",
    "    # Merge filtered_idx_cons and etf_cons_adjusted\n",
    "    merged = filtered_idx_cons.merge(etf_cons_adjusted, on='ISIN', suffixes=('_idx', '_etf'))\n",
    "    \n",
    "    # Calculate minimum weight for each ISIN pair\n",
    "    merged['MIN_WEIGHT'] = merged[['WEIGHT_idx', 'WEIGHT_etf']].min(axis=1)\n",
    "\n",
    "    # Calculate total overlap for each ETF\n",
    "    etf_overlaps = merged.groupby('INDEXID_etf')['MIN_WEIGHT'].sum().reset_index()\n",
    "    etf_overlaps.rename(columns={'INDEXID_etf': 'ETFSymbol', 'MIN_WEIGHT': 'OVERLAP'}, inplace=True)\n",
    "    \n",
    "    # Assign INDEXID_x\n",
    "    etf_overlaps['INDEXID_x'] = idx_id\n",
    "\n",
    "    # Sort by OVERLAP in descending order and calculate RANK\n",
    "    etf_overlaps = etf_overlaps.sort_values(by='OVERLAP', ascending=False).reset_index(drop=True)\n",
    "    etf_overlaps['RANK'] = etf_overlaps['OVERLAP'].rank(method='dense', ascending=False)\n",
    "    \n",
    "    # Reorder columns to match idx_overlaps format\n",
    "    etf_overlaps = etf_overlaps[['INDEXID_x', 'ETFSymbol', 'OVERLAP', 'RANK']]\n",
    "\n",
    "    return etf_overlaps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5fadc4ea-a98a-4de7-b92b-7a2e91c6241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get index to index returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd12787a-7df4-4b9d-b816-e73860e0d406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_analysis(idx_id, idx_cons, idx_catalog, idx_returns):\n",
    "    # Perform index overlap analysis\n",
    "    idx_overlaps = analyze_index_overlap(idx_id, idx_cons, idx_catalog)\n",
    "\n",
    "    # Proceed with merging returns data\n",
    "    idx_returns['DATE'] = pd.to_datetime(idx_returns['DATE'])\n",
    "    idx_overlaps_with_returns = pd.merge(idx_overlaps, idx_returns, left_on='INDEXID', right_on='INDEXID', how='left', suffixes=('', '_return'))\n",
    "    idx_overlaps_with_all_returns = pd.merge(idx_overlaps_with_returns, idx_returns, left_on=['INDEXID_x', 'DATE'], right_on=['INDEXID', 'DATE'], how='left', suffixes=('_return_b', '_return_a'))\n",
    "\n",
    "    # Rename and clean up columns as previously described\n",
    "    idx_overlaps_with_all_returns.rename(columns={\n",
    "        'INDEXRETURN1D_return_b': 'MatchedIndexReturn',\n",
    "        'INDEXRETURN1D_return_a': 'OriginalIndexReturn',\n",
    "        'INDEXID_return_b': 'MatchedIndex',\n",
    "        'INDEXID_x': 'OriginalIndex'\n",
    "    }, inplace=True)\n",
    "    idx_analysis = idx_overlaps_with_all_returns.drop(['RANK', 'UniqueIndexB', 'MatchID', 'INDEXID_return_a'], axis=1)\n",
    "    idx_analysis['InstrumentType']='Index'\n",
    "    return idx_analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a15074c5-f8cd-4849-8840-d8853a793eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get index to etf returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "34856fc7-a81c-41a7-b788-f0b7d589ee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def complete_etf_analysis(idx_id, idx_cons, etf_cons, idx_catalog, etf_returns, idx_returns):\n",
    "    \"\"\"\n",
    "    Perform analysis to compare index overlaps with ETFs and their respective returns.\n",
    "\n",
    "    Parameters:\n",
    "    - idx_id: The ID of the index to analyze.\n",
    "    - idx_cons: DataFrame containing index constituents information.\n",
    "    - etf_cons: DataFrame containing ETF constituents information.\n",
    "    - idx_catalog: DataFrame with index catalog information.\n",
    "    - etf_returns: DataFrame containing ETF returns information.\n",
    "    - idx_returns: DataFrame containing index returns information.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame containing overlaps and return comparisons.\n",
    "    \"\"\"\n",
    "    # Generate ETF overlaps\n",
    "    etf_overlaps = analyze_index_etf_overlap(idx_id, idx_cons, etf_cons, idx_catalog)\n",
    "\n",
    "    # Prepare etf_returns DataFrame\n",
    "    etf_returns['DATE'] = pd.to_datetime(etf_returns['DATE'])\n",
    "\n",
    "    # Merge ETF overlaps with ETF returns\n",
    "    etf_overlaps_with_returns = pd.merge(etf_overlaps, etf_returns, left_on='ETFSymbol', right_on='ETFSYMBOL', how='left', suffixes=('', '_etf'))\n",
    "    \n",
    "    # Prepare idx_returns DataFrame\n",
    "    idx_returns['DATE'] = pd.to_datetime(idx_returns['DATE'])\n",
    "\n",
    "    # Correct the merge to use consistent column names\n",
    "    # Assuming 'IndexID' should match 'INDEXID_x' from etf_overlaps and 'DATE' is correct\n",
    "    etf_overlaps_with_all_returns = pd.merge(etf_overlaps_with_returns, idx_returns, left_on=['INDEXID_x', 'DATE'], right_on=['INDEXID', 'DATE'], how='left')\n",
    "\n",
    "\n",
    "    \n",
    "    # Select relevant columns to match your desired output format\n",
    "    etf_analysis = etf_overlaps_with_all_returns[['DATE','INDEXID_x', 'ETFSymbol', 'OVERLAP', 'ETFRETURN1D', 'INDEXRETURN1D']]\n",
    "    etf_analysis.loc[:, 'InstrumentType'] = 'ETF'\n",
    "    return etf_analysis\n",
    "\n",
    "#idx_id='STXX|ESTX|PI'\n",
    "#combined_statistics = complete_etf_analysis(idx_id, idx_cons, etf_cons, idx_catalog, etf_returns, idx_returns)\n",
    "#print(combined_statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f9d8092f-8e70-4338-918b-58d395c65143",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get etf to index returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "072477e3-8d8e-4f07-bb16-57540cdeef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def complete_etf_to_index_returns_analysis(idx_id, idx_cons, etf_cons, idx_catalog, etf_returns, idx_returns):\n",
    "    \"\"\"\n",
    "    Perform analysis to compare ETF overlaps with indexes and their respective returns.\n",
    "    \n",
    "    Parameters:\n",
    "    - idx_id: The ID of the ETF to analyze.\n",
    "    - idx_cons: DataFrame containing index constituents information.\n",
    "    - etf_cons: DataFrame containing ETF constituents information.\n",
    "    - idx_catalog: DataFrame with index catalog information.\n",
    "    - etf_returns: DataFrame containing ETF returns information.\n",
    "    - idx_returns: DataFrame containing index returns information.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing overlaps and return comparisons for an ETF against indexes.\n",
    "    \"\"\"\n",
    "    # Generate ETF overlaps against indexes\n",
    "    etf_index_overlaps = analyze_etf_index_overlap(idx_id, idx_cons, etf_cons, idx_catalog)\n",
    "\n",
    "    # Prepare ETF returns DataFrame\n",
    "    etf_returns['DATE'] = pd.to_datetime(etf_returns['DATE'])\n",
    "    # Filter ETF returns for the specific ETF\n",
    "    specific_etf_returns = etf_returns[etf_returns['ETFSYMBOL'] == idx_id]\n",
    "\n",
    "    # Prepare Index returns DataFrame\n",
    "    idx_returns['DATE'] = pd.to_datetime(idx_returns['DATE'])\n",
    "\n",
    "    # Merge ETF overlaps with Index returns\n",
    "    etf_index_overlaps_with_returns = pd.merge(etf_index_overlaps, idx_returns, left_on='INDEXID', right_on='INDEXID', how='left', suffixes=('', '_idx_return'))\n",
    "\n",
    "    # Merge the result with specific ETF returns\n",
    "    final_analysis = pd.merge(etf_index_overlaps_with_returns, specific_etf_returns[['DATE', 'ETFSYMBOL', 'ETFRETURN1D']], on=['DATE'], how='left')\n",
    "\n",
    "    # Rename and clean up columns for clarity\n",
    "    final_analysis.rename(columns={\n",
    "        'INDEXID': 'INDEXID_x'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Add 'InstrumentType' column for consistency\n",
    "    final_analysis['InstrumentType'] = 'ETF'\n",
    "\n",
    "    # Select relevant columns to match your desired output format\n",
    "    etf_to_index_analysis = final_analysis[['DATE', 'INDEXID_x', 'ETFSymbol', 'OVERLAP', 'ETFRETURN1D', 'INDEXRETURN1D', 'InstrumentType']]\n",
    "    \n",
    "    return etf_to_index_analysis\n",
    "\n",
    "\n",
    "#idx_id='ETFBIS|EWP'\n",
    "#combined_statistics = complete_etf_to_index_returns_analysis(idx_id, idx_cons, etf_cons, idx_catalog, etf_returns, idx_returns)\n",
    "#print(combined_statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "35c3a5e9-5dcd-4ed1-82b5-fd7bc56b6233",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate combined index and etf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1aa68a69-97cb-42ba-af54-5e028e32fd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_combined_statistics(idx_id, idx_cons, etf_cons, idx_catalog, etf_returns, idx_returns):\n",
    "    \"\"\"\n",
    "    Calculate statistics for both index-to-index and index-to-ETF overlaps,\n",
    "    and merge back into a unified dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - idx_id: The ID of the index to analyze.\n",
    "    - idx_cons: DataFrame containing index constituents information.\n",
    "    - etf_cons: DataFrame containing ETF constituents information.\n",
    "    - idx_catalog: DataFrame with index and ETF catalog information.\n",
    "    - etf_returns: DataFrame containing ETF returns information.\n",
    "    - idx_returns: DataFrame containing index returns information.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with merged statistics for both index-to-index and index-to-ETF comparisons.\n",
    "    \"\"\"\n",
    "    # Generate index-to-index overlaps and returns analysis\n",
    "    idx_overlaps = analyze_index_overlap(idx_id, idx_cons, idx_catalog)\n",
    "    etf_overlaps= analyze_index_etf_overlap(idx_id, idx_cons, etf_cons, idx_catalog)\n",
    "    idx_analysis = complete_analysis(idx_id, idx_cons, idx_catalog, idx_returns)\n",
    "    \n",
    "    etf_analysis = complete_etf_analysis(idx_id, idx_cons, etf_cons, idx_catalog, etf_returns, idx_returns)\n",
    "\n",
    "#combine etf analysis\n",
    "    \n",
    "\n",
    "    etf_analysis.rename(columns={\n",
    "        'ETFSymbol': 'MatchedIndex',\n",
    "        'ETFRETURN1D': 'MatchedIndexReturn',\n",
    "        'INDEXRETURN1D': 'OriginalIndexReturn',\n",
    "        'DATE':'Date_return_a',\n",
    "        'Date_return':'Date_return_b',\n",
    "        'INDEXID_x':'OriginalIndex'\n",
    "    }, inplace=True)\n",
    "\n",
    "\n",
    "    # Ensure DATE columns are standardized and correctly formatted\n",
    "    etf_analysis['Date_return_a'] = pd.to_datetime(etf_analysis['Date_return_a'])\n",
    "    \n",
    "\n",
    "    # Combine the index-to-index and index-to-ETF analysis data\n",
    "    combined_analysis = pd.concat([idx_analysis, etf_analysis], ignore_index=True)\n",
    "\n",
    "    # Calculate statistics (mean, std deviation, covariance, correlation) on the combined dataset\n",
    "    # [Your existing statistical calculations here, adapted for the combined_analysis DataFrame]\n",
    "\n",
    "    # Ensure to adjust the column names and calculations to align with the combined structure\n",
    "    # For example, you might need to handle differently named columns for returns or identifiers\n",
    "# Calculate Means\n",
    "    means = combined_analysis.groupby(['OriginalIndex', 'MatchedIndex']).agg(\n",
    "        Avg_Original=('OriginalIndexReturn', 'mean'),\n",
    "        Avg_Matched=('MatchedIndexReturn', 'mean')\n",
    "    ).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "    # Join back for deviation calculations\n",
    "    combined = pd.merge(combined_analysis, means, on=['OriginalIndex', 'MatchedIndex'])\n",
    "\n",
    "    \n",
    "    # Calculate deviations\n",
    "    combined['Deviation_Original'] = combined['OriginalIndexReturn'] - combined['Avg_Original']\n",
    "    combined['Deviation_Matched'] = combined['MatchedIndexReturn'] - combined['Avg_Matched']\n",
    "\n",
    "    # Standard Deviations within each group\n",
    "    std_devs = combined.groupby(['OriginalIndex', 'MatchedIndex']).agg(\n",
    "        StdDev_Original=('Deviation_Original', lambda x: np.sqrt(np.sum(x**2) / (x.count()-1))),\n",
    "        StdDev_Matched=('Deviation_Matched', lambda x: np.sqrt(np.sum(x**2) / (x.count()-1)))\n",
    "    ).reset_index()\n",
    "\n",
    "    \n",
    "    # Correct Covariance Calculation within each group\n",
    "    def calculate_group_covariance(group):\n",
    "        denominator = (len(group) - 1)\n",
    "        if denominator > 0:\n",
    "            return np.sum(group['Deviation_Original'] * group['Deviation_Matched']) / denominator\n",
    "        else:\n",
    "            return np.nan  # Or appropriate default value, like 0\n",
    "\n",
    "    covariance = combined.groupby(['OriginalIndex', 'MatchedIndex']).apply(calculate_group_covariance).reset_index(name='Cov_AB')\n",
    "\n",
    "    # Merge Covariance and Standard Deviations for Correlation Calculation\n",
    "    correlation = pd.merge(covariance, std_devs, on=['OriginalIndex', 'MatchedIndex'])\n",
    "\n",
    "    # Calculate Correlation Coefficient for each group\n",
    "    correlation['CorrelationCoefficient'] = correlation['Cov_AB'] / (correlation['StdDev_Original'] * correlation['StdDev_Matched'])\n",
    "\n",
    "    \n",
    "    # Index specific - remove return types\n",
    "    idx_statistics = pd.merge(idx_overlaps, correlation, \n",
    "                           left_on=['INDEXID_x', 'INDEXID'], \n",
    "                           right_on=['OriginalIndex', 'MatchedIndex'], \n",
    "                           how='left')\n",
    "\n",
    "    \n",
    "    def extract_before_second_pipe(index_id):\n",
    "        parts = index_id.split('|')\n",
    "        return '|'.join(parts[:2])\n",
    "\n",
    "    idx_statistics['OriginalIndex_BeforeSecondPipe'] = idx_statistics['OriginalIndex'].apply(extract_before_second_pipe)\n",
    "    idx_statistics['MatchedIndex_BeforeSecondPipe'] = idx_statistics['MatchedIndex'].apply(extract_before_second_pipe)\n",
    "\n",
    "    idx_statistics = idx_statistics[idx_statistics['OriginalIndex_BeforeSecondPipe'] != idx_statistics['MatchedIndex_BeforeSecondPipe']]\n",
    "\n",
    "    #calculate etf statistics\n",
    "\n",
    "    etf_statistics = pd.merge(etf_overlaps, correlation, \n",
    "                           left_on='ETFSymbol', right_on='MatchedIndex', \n",
    "                           how='left')\n",
    "    \n",
    "    etf_statistics = pd.merge(etf_statistics, etf_catalog, \n",
    "                           left_on='ETFSymbol', right_on='ETFSYMBOL', \n",
    "                           how='left')\n",
    "\n",
    "\n",
    "\n",
    "    # Select relevant columns\n",
    "    idx_statistics = idx_statistics[['OriginalIndex', 'MatchedIndex', 'DESCRIPTION', 'OVERLAP', 'CorrelationCoefficient']]\n",
    "\n",
    "    etf_statistics = pd.merge(\n",
    "        etf_statistics,\n",
    "        idx_catalog[['INDEXID', 'DESCRIPTION']].rename(columns={'DESCRIPTION': 'OriginalIndexDescription', 'INDEXID': 'OriginalIndexID'}),\n",
    "        left_on='OriginalIndex',\n",
    "        right_on='OriginalIndexID',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    etf_statistics['MatchedInstrumentType']='ETF'\n",
    "    \n",
    "    idx_statistics = pd.merge(\n",
    "        idx_statistics,\n",
    "        idx_catalog[['INDEXID', 'DESCRIPTION']].rename(columns={'DESCRIPTION': 'OriginalIndexDescription', 'INDEXID': 'OriginalIndexID'}),\n",
    "        left_on='OriginalIndex',\n",
    "        right_on='OriginalIndexID',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    \n",
    "    idx_statistics['MatchedInstrumentType']='Index'\n",
    "    \n",
    "    combined_statistics = pd.concat([etf_statistics, idx_statistics], ignore_index=True)\n",
    "\n",
    "    combined_statistics.rename(columns={\n",
    "        'DESCRIPTION': 'MatchedDescription',\n",
    "        'OVERLAP': 'OverlapPercentage',\n",
    "        'MatchedIndex': 'MatchedID',\n",
    "        'CorrelationCoefficient': 'PearsonCoefficient'\n",
    "    }, inplace=True)\n",
    "\n",
    "\n",
    "#convert overlap to percentage\n",
    "\n",
    "    combined_statistics['OverlapPercentage'] = combined_statistics['OverlapPercentage']*100\n",
    "    \n",
    "    combined_statistics = combined_statistics[[\n",
    "        'MatchedInstrumentType',\n",
    "        'OriginalIndexDescription',\n",
    "        'MatchedDescription',\n",
    "        'OverlapPercentage',\n",
    "        'PearsonCoefficient',\n",
    "        'OriginalIndexID',\n",
    "        'MatchedID'\n",
    "    ]]\n",
    "    \n",
    "    return combined_statistics\n",
    "#ETFBIS|EWP 'STXX|ESTX|PI'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ed06236d-e319-423a-99ef-66c742b9dfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_etf_statistics(idx_id, idx_cons, etf_cons, idx_catalog, etf_returns, idx_returns):\n",
    "    \"\"\"\n",
    "    Calculate statistics for both index-to-index and index-to-ETF overlaps,\n",
    "    and merge back into a unified dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - idx_id: The ID of the index to analyze.\n",
    "    - idx_cons: DataFrame containing index constituents information.\n",
    "    - etf_cons: DataFrame containing ETF constituents information.\n",
    "    - idx_catalog: DataFrame with index and ETF catalog information.\n",
    "    - etf_returns: DataFrame containing ETF returns information.\n",
    "    - idx_returns: DataFrame containing index returns information.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with merged statistics for both index-to-index and index-to-ETF comparisons.\n",
    "    \"\"\"\n",
    "    # Generate index-to-index overlaps and returns analysis\n",
    "    etf_overlaps= analyze_etf_index_overlap(idx_id, idx_cons, etf_cons, idx_catalog)\n",
    "    etf_to_index_analysis = complete_etf_to_index_returns_analysis(idx_id, idx_cons, etf_cons, idx_catalog, etf_returns, idx_returns)\n",
    "\n",
    "#combine etf analysis\n",
    "    \n",
    "    \n",
    "    etf_to_index_analysis.rename(columns={\n",
    "        'ETFRETURN1D': 'MatchedIndexReturn',\n",
    "        'INDEXRETURN1D': 'OriginalIndexReturn',\n",
    "        'DATE':'Date_return_a',\n",
    "        'Date_return':'Date_return_b',\n",
    "        'INDEXID_x':'OriginalIndex',\n",
    "        'ETFSymbol':'MatchedIndex'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Ensure DATE columns are standardized and correctly formatted\n",
    "    etf_to_index_analysis['Date_return_a'] = pd.to_datetime(etf_to_index_analysis['Date_return_a'])\n",
    "    \n",
    "    # Calculate statistics (mean, std deviation, covariance, correlation) on the combined dataset\n",
    "    # [Your existing statistical calculations here, adapted for the combined_analysis DataFrame]\n",
    "\n",
    "    # Ensure to adjust the column names and calculations to align with the combined structure\n",
    "    # For example, you might need to handle differently named columns for returns or identifiers\n",
    "# Calculate Means\n",
    "    means = etf_to_index_analysis.groupby(['MatchedIndex', 'OriginalIndex']).agg(\n",
    "        Avg_Original=('MatchedIndexReturn', 'mean'),\n",
    "        Avg_Matched=('OriginalIndexReturn', 'mean')\n",
    "    ).reset_index()\n",
    "\n",
    "    \n",
    "\n",
    "    # Join back for deviation calculations\n",
    "    combined = pd.merge(etf_to_index_analysis, means, on=['OriginalIndex', 'MatchedIndex'])\n",
    "\n",
    "    \n",
    "    # Calculate deviations\n",
    "    combined['Deviation_Original'] = combined['OriginalIndexReturn'] - combined['Avg_Original']\n",
    "    combined['Deviation_Matched'] = combined['MatchedIndexReturn'] - combined['Avg_Matched']\n",
    "\n",
    "    # Standard Deviations within each group\n",
    "    std_devs = combined.groupby(['OriginalIndex', 'MatchedIndex']).agg(\n",
    "        StdDev_Original=('Deviation_Original', lambda x: np.sqrt(np.sum(x**2) / (x.count()-1))),\n",
    "        StdDev_Matched=('Deviation_Matched', lambda x: np.sqrt(np.sum(x**2) / (x.count()-1)))\n",
    "    ).reset_index()\n",
    "\n",
    "    \n",
    "    # Correct Covariance Calculation within each group\n",
    "    def calculate_group_covariance(group):\n",
    "        denominator = (len(group) - 1)\n",
    "        if denominator > 0:\n",
    "            return np.sum(group['Deviation_Original'] * group['Deviation_Matched']) / denominator\n",
    "        else:\n",
    "            return np.nan  # Or appropriate default value, like 0\n",
    "\n",
    "    covariance = combined.groupby(['OriginalIndex', 'MatchedIndex']).apply(calculate_group_covariance).reset_index(name='Cov_AB')\n",
    "\n",
    "    # Merge Covariance and Standard Deviations for Correlation Calculation\n",
    "    correlation = pd.merge(covariance, std_devs, on=['OriginalIndex', 'MatchedIndex'])\n",
    "\n",
    "    # Calculate Correlation Coefficient for each group\n",
    "    correlation['CorrelationCoefficient'] = correlation['Cov_AB'] / (correlation['StdDev_Original'] * correlation['StdDev_Matched'])\n",
    "    \n",
    "     #Index specific - remove return types\n",
    "    \n",
    "    etf_statistics = pd.merge(etf_overlaps, correlation, \n",
    "                           left_on='ETFSymbol', right_on='MatchedIndex', \n",
    "                           how='left')\n",
    "    \n",
    "\n",
    "    #calculate etf statistics\n",
    "\n",
    "\n",
    "    etf_statistics = pd.merge(etf_statistics, etf_catalog, \n",
    "                           left_on='ETFSymbol', right_on='ETFSYMBOL', \n",
    "                           how='left')\n",
    "\n",
    "\n",
    "    etf_statistics = pd.merge(\n",
    "        etf_statistics,\n",
    "        idx_catalog[['INDEXID', 'DESCRIPTION']].rename(columns={'DESCRIPTION': 'OriginalIndexDescription', 'INDEXID': 'OriginalIndexID'}),\n",
    "        left_on='OriginalIndex',\n",
    "        right_on='OriginalIndexID',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    etf_statistics['MatchedInstrumentType']='Index'\n",
    "    \n",
    "\n",
    "    etf_statistics.rename(columns={\n",
    "        'DESCRIPTION': 'OriginalDescription',\n",
    "        'OriginalIndexDescription':'MatchedDescription',\n",
    "        'OVERLAP': 'OverlapPercentage',\n",
    "        'MatchedIndex': 'OriginalID',\n",
    "        'OriginalIndexID':'MatchedID',\n",
    "        'CorrelationCoefficient': 'PearsonCoefficient'\n",
    "        \n",
    "    }, inplace=True)\n",
    "\n",
    "\n",
    "#convert overlap to percentage\n",
    "\n",
    "    etf_statistics['OverlapPercentage'] = etf_statistics['OverlapPercentage']*100\n",
    "    \n",
    "    etf_statistics = etf_statistics[[\n",
    "        'MatchedInstrumentType',\n",
    "        'OriginalDescription',\n",
    "        'MatchedDescription',\n",
    "        'OverlapPercentage',\n",
    "        'PearsonCoefficient',\n",
    "        'OriginalID',\n",
    "        'MatchedID'\n",
    "    ]]\n",
    "    \n",
    "    return etf_statistics\n",
    "#ETFBIS|EWP 'STXX|ESTX|PI'\n",
    "#idx_id='ETFBIS|EWP'\n",
    "#combined_statistics = calculate_etf_statistics(idx_id, idx_cons, etf_cons, idx_catalog, etf_returns, idx_returns)\n",
    "#print(combined_statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e3190929-5109-4882-b412-91a2b2bf4465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a061732fea0b4316b8dec86f4206bf23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Type:', options=('Index', 'ETF'), value='Index')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b33861543274d8ba117ca17488070eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Filter:', placeholder='Type to filter')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ef63688277419aadac3f0965b56950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='INDEXID:', options=('COMMUNICATION SERVICES SELECT SECTOR INDEX (5S25.US.SC00L.50)', 'COâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3697e7fdd5c54991b0e8abe9dadd7175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=True, description='Index')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee334cd2f98499d9ee744de33eab905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=True, description='ETF')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c2e7294f3d4080adb573ea7c87d51a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=True, description='Alternatives')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664704d5ae0843b797f21623484124c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Assuming the necessary DataFrames and functions are defined\n",
    "filtered_idx_catalog = idx_catalog[idx_catalog['INDEXID'].isin(idx_cons['INDEXID'].unique())]\n",
    "filtered_idx_catalog = filtered_idx_catalog[~filtered_idx_catalog['INDEXID'].str.contains('CRPI', case=False)]\n",
    "\n",
    "# Checkboxes for selecting InstrumentType\n",
    "checkbox_index = widgets.Checkbox(value=True, description='Index')\n",
    "checkbox_etf = widgets.Checkbox(value=True, description='ETF')\n",
    "checkbox_alternatives = widgets.Checkbox(value=True, description='Alternatives')\n",
    "\n",
    "# Dropdown for selecting InstrumentType\n",
    "dropdown_type = widgets.Dropdown(\n",
    "    options=['Index', 'ETF'],\n",
    "    description='Type:'\n",
    ")\n",
    "\n",
    "# Text input for filtering IndexID or ETF Symbol\n",
    "text_filter = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type to filter',\n",
    "    description='Filter:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Dropdown for displaying filtered IndexID or ETF Symbol; initially empty\n",
    "dropdown_index = widgets.Dropdown(\n",
    "    options=[],\n",
    "    description='INDEXID:'\n",
    ")\n",
    "\n",
    "# Initial setup for dropdown options based on the default selection\n",
    "display_to_original = {}\n",
    "\n",
    "def update_dropdown_options(*args):\n",
    "    global display_to_original\n",
    "    display_to_original.clear()\n",
    "    filter_text = text_filter.value.upper()\n",
    "    options = []\n",
    "    unique_display_texts = set()  # Set to keep track of unique display texts\n",
    "\n",
    "    if dropdown_type.value == 'Index':\n",
    "        for _, row in filtered_idx_catalog.iterrows():\n",
    "            symbol = row['INDEXID'].split('|')[1] if '|' in row['INDEXID'] else row['INDEXID']\n",
    "            display_text = f\"{row['DESCRIPTION']} ({symbol})\"\n",
    "            if (filter_text in row['DESCRIPTION'].upper() or filter_text in row['INDEXID'].upper()) and (display_text not in unique_display_texts):\n",
    "                options.append((display_text, row['INDEXID']))  # Store with original INDEXID for later retrieval\n",
    "                display_to_original[display_text] = row['INDEXID']\n",
    "                unique_display_texts.add(display_text)  # Mark this display text as seen\n",
    "    elif dropdown_type.value == 'ETF':\n",
    "        for _, row in etf_catalog.iterrows():\n",
    "            symbol = row['ETFSYMBOL'].split('|')[1] if '|' in row['ETFSYMBOL'] else row['ETFSYMBOL']\n",
    "            display_text = f\"{row['DESCRIPTION']} ({symbol})\"\n",
    "            if (filter_text in row['DESCRIPTION'].upper() or filter_text in row['ETFSYMBOL'].upper()) and (display_text not in unique_display_texts):\n",
    "                options.append((display_text, row['ETFSYMBOL']))  # Store with original ETFSYMBOL for later retrieval\n",
    "                display_to_original[display_text] = row['ETFSYMBOL']\n",
    "                unique_display_texts.add(display_text)  # Mark this display text as seen\n",
    "\n",
    "    # Sort options by DESCRIPTION part (the text before ' (')\n",
    "    sorted_options = sorted(options, key=lambda x: x[0].split(' (')[0])\n",
    "\n",
    "    # Update dropdown options; the value displayed to the user is the first element of each tuple\n",
    "    dropdown_index.options = [option[0] for option in sorted_options]\n",
    "\n",
    "\n",
    "def on_filter_change(change):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        # Retrieve the original identifier from the selected display text\n",
    "        selected_display_text = dropdown_index.value\n",
    "        idx_id = display_to_original.get(selected_display_text, \"\")\n",
    "        # Determine which instrument types are selected\n",
    "        selected_types = []\n",
    "        if checkbox_index.value:\n",
    "            selected_types.append('Index')\n",
    "        if checkbox_etf.value:\n",
    "            selected_types.append('ETF')\n",
    "        # Call the combined_statistics function with the selected idx_id\n",
    "        if dropdown_type.value == 'Index':\n",
    "            combined_statistics = calculate_combined_statistics(idx_id, idx_cons, etf_cons, idx_catalog, etf_returns, idx_returns)\n",
    "        elif dropdown_type.value == 'ETF':\n",
    "            combined_statistics = calculate_etf_statistics(idx_id, idx_cons, etf_cons, idx_catalog, etf_returns, idx_returns)\n",
    "        # Filter combined_statistics by selected instrument types\n",
    "        if selected_types:\n",
    "            filtered_statistics = combined_statistics[combined_statistics['MatchedInstrumentType'].isin(selected_types)]\n",
    "        else:\n",
    "            filtered_statistics = pd.DataFrame()  # Empty DataFrame if no types are selected\n",
    "        \n",
    "        # Calculate the index of the max 'PearsonCoefficient' for each 'MatchedDescription'\n",
    "        max_idx = filtered_statistics.groupby('MatchedDescription')['PearsonCoefficient'].idxmax()\n",
    "        \n",
    "        # Drop NaN values from max_idx to avoid KeyError when using .loc[]\n",
    "        max_idx = max_idx.dropna()\n",
    "        \n",
    "        # Use the filtered max_idx to index into filtered_statistics\n",
    "        filtered_statistics = filtered_statistics.loc[max_idx]\n",
    "        if not filtered_statistics.empty:\n",
    "            # Sort by custom criterion: (OverlapPercentage/100) + PearsonCoefficient\n",
    "            filtered_statistics = (\n",
    "                filtered_statistics.assign(\n",
    "                CustomSortCriterion=lambda x: (x['OverlapPercentage']/100) + x['PearsonCoefficient']\n",
    "            )\n",
    "            .sort_values(by='CustomSortCriterion', ascending=False)\n",
    ")\n",
    "\n",
    "            top_filtered_statistics = filtered_statistics.head(20)\n",
    "\n",
    "# Optionally, if you want to drop the CustomSortCriterion column from the top 20 results\n",
    "            top_filtered_statistics = top_filtered_statistics.drop(columns=['CustomSortCriterion'])\n",
    "            display(top_filtered_statistics)\n",
    "        \n",
    "# Call update_dropdown_options when the type is changed or text is entered for filtering\n",
    "dropdown_type.observe(update_dropdown_options, 'value')\n",
    "text_filter.observe(update_dropdown_options, 'value')\n",
    "dropdown_index.observe(on_filter_change, names='value')\n",
    "checkbox_index.observe(on_filter_change, names='value')\n",
    "checkbox_etf.observe(on_filter_change, names='value')\n",
    "checkbox_alternatives.observe(on_filter_change, names='value')\n",
    "dropdown_index.observe(on_filter_change, names='value')\n",
    "checkbox_index.observe(on_filter_change, names='value')\n",
    "checkbox_etf.observe(on_filter_change, names='value')\n",
    "checkbox_alternatives.observe(on_filter_change, names='value')\n",
    "\n",
    "# Initial call to populate dropdown options\n",
    "update_dropdown_options()\n",
    "\n",
    "# Placeholder to display the DataFrame or any other output\n",
    "output = widgets.Output()\n",
    "\n",
    "# Your existing logic for on_value_change and on_filter_change here\n",
    "\n",
    "# Display the widgets and output placeholder\n",
    "display(dropdown_type, text_filter, dropdown_index, checkbox_index, checkbox_etf, checkbox_alternatives, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0321828-1061-4a88-aa3e-2e6c2b98a609",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
